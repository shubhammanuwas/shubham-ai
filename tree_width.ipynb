{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shubhammanuwas/shubham-ai/blob/main/tree_width.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1YQ5BpD8zaxk",
        "outputId": "1e3535c2-f98c-4951-9921-44017c6e1299"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.3.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.18.1+cu121)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.10.0.84)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (9.4.0)\n",
            "Collecting segment-anything\n",
            "  Downloading segment_anything-1.0-py3-none-any.whl.metadata (487 bytes)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.1)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch) (2.3.1)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.6.20-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Downloading segment_anything-1.0-py3-none-any.whl (36 kB)\n",
            "Using cached nvidia_nvjitlink_cu12-12.6.20-py3-none-manylinux2014_x86_64.whl (19.7 MB)\n",
            "Installing collected packages: segment-anything, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.6.20 nvidia-nvtx-cu12-12.1.105 segment-anything-1.0\n"
          ]
        }
      ],
      "source": [
        "pip install torch torchvision opencv-python pillow segment-anything\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mR5jKiGu4O0I",
        "outputId": "577ca451-ca5d-4c00-f56e-542d25fdc3b8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "HOME: /content\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "HOME = os.getcwd()\n",
        "print(\"HOME:\", HOME)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fT_Ddskl4dJS",
        "outputId": "6e34781c-bf96-4b9f-a5cc-a3aff7d46b46"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install -q 'git+https://github.com/facebookresearch/segment-anything.git'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ACyI5MUF4tht"
      },
      "outputs": [],
      "source": [
        "!mkdir -p {HOME}/weights\n",
        "!wget -q https://dl.fbaipublicfiles.com/segment_anything/sam_vit_b_01ec64.pth -P {HOME}/weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3t2sVuq55C9t",
        "outputId": "37268238-3e6d-40e9-e165-c8cf7b3f9c5b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/weights/sam_vit_b_01ec64.pth ; exist: True\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "CHECKPOINT_PATH = os.path.join(HOME, \"weights\", \"sam_vit_b_01ec64.pth\")\n",
        "print(CHECKPOINT_PATH, \"; exist:\", os.path.isfile(CHECKPOINT_PATH))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4VIbXwWiZHz0",
        "outputId": "2ffb47f0-11f2-40b1-df9d-88e42f6f35bb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded 10 images.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "\n",
        "# Define the path to the images folder\n",
        "images_folder = \"/content/images\"\n",
        "\n",
        "# Get all image paths from the folder\n",
        "image_paths = [os.path.join(images_folder, file) for file in os.listdir(images_folder) if file.endswith(('.jpeg', '.jpg', '.png'))]\n",
        "\n",
        "# Load all images into a list\n",
        "images = [Image.open(image_path) for image_path in image_paths]\n",
        "\n",
        "print(f\"Loaded {len(images)} images.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "drcePp7a0z-A",
        "outputId": "98edd9f4-e593-4d8e-9556-b002a94cbebc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Image path:/content/images/tree3.jpeg\n",
            "Image size: (960, 1280)\n",
            "Image Width: 960\n",
            "Image Dimensions: 960 x 1280\n",
            "Estimated Pixel Width of Tree Trunk: 687 pixels\n",
            "Estimated Real-World Diameter of Tree Trunk: 11.27 cm\n"
          ]
        }
      ],
      "source": [
        "from PIL import Image, ImageDraw\n",
        "import numpy as np\n",
        "import torch\n",
        "import cv2\n",
        "from segment_anything import sam_model_registry, SamAutomaticMaskGenerator\n",
        "\n",
        "# Load the image using a relative path\n",
        "image_path = \"/content/images/tree3.jpeg\"  # Assuming the image is in the \"images\" folder in your working directory\n",
        "image = Image.open(image_path)\n",
        "image_np = np.array(image)\n",
        "\n",
        "# The rest of your code remains the same\n",
        "print(f\"Image path:{image_path}\")\n",
        "print(f\"Image size: {image.size}\")\n",
        "print(f\"Image Width: {image.width}\")\n",
        "\n",
        "# Step 2: Load the SAM model\n",
        "\n",
        "\n",
        "DEVICE = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "MODEL_TYPE = \"vit_b\"\n",
        "sam = sam_model_registry[MODEL_TYPE](checkpoint=CHECKPOINT_PATH).to(device=DEVICE)\n",
        "\n",
        "\n",
        "# Step 3: Generate masks using SAM\n",
        "mask_generator = SamAutomaticMaskGenerator(sam)\n",
        "masks = mask_generator.generate(image_np)\n",
        "\n",
        "# Step 4: Identify the tree trunk (largest segmented object)\n",
        "largest_mask = max(masks, key=lambda x: x['area'])['segmentation']\n",
        "\n",
        "# Step 5: Calculate the bounding box of the tree trunk\n",
        "x, y, w, h = cv2.boundingRect(largest_mask.astype(np.uint8))\n",
        "tree_trunk_pixel_width = w  # Width of the tree trunk in pixels\n",
        "\n",
        "# Step 6: Convert pixel width to real-world measurement (in cm)\n",
        "focal_length_cm = 2.4  # Focal length in cm\n",
        "object_distance_cm = 50  # Distance to the object in cm\n",
        "sensor_width_cm = 0.756  # Sensor width in cm\n",
        "\n",
        "# Calculate the focal length in pixels\n",
        "focal_length_pixels = (focal_length_cm * image.width) / sensor_width_cm\n",
        "\n",
        "# Calculate the real-world width in cm using the corrected formula\n",
        "real_world_width_cm = (tree_trunk_pixel_width * object_distance_cm) / focal_length_pixels\n",
        "\n",
        "# Step 7: Estimate the diameter (assuming the tree trunk is roughly circular)\n",
        "tree_trunk_diameter_cm = real_world_width_cm\n",
        "\n",
        "# Print the results\n",
        "print(f\"Image Dimensions: {image.width} x {image.height}\")\n",
        "print(f\"Estimated Pixel Width of Tree Trunk: {tree_trunk_pixel_width} pixels\")\n",
        "print(f\"Estimated Real-World Diameter of Tree Trunk: {tree_trunk_diameter_cm:.2f} cm\")\n",
        "\n",
        "# Step 8: Visualize the segmentation and the diameter line\n",
        "# Convert the mask to an image\n",
        "mask_image = Image.fromarray((largest_mask * 255).astype(np.uint8))\n",
        "\n",
        "# Create an overlay of the mask on the original image\n",
        "overlay = Image.fromarray(cv2.addWeighted(image_np, 0.5, np.array(mask_image.convert('RGB')), 0.5, 0))\n",
        "\n",
        "# Draw the bounding box and the diameter line on the overlay\n",
        "draw = ImageDraw.Draw(overlay)\n",
        "draw.rectangle([x, y, x + w, y + h], outline=\"red\", width=3)  # Bounding box in red\n",
        "draw.line([x, y + h//2, x + w, y + h//2], fill=\"blue\", width=3)  # Diameter line in blue\n",
        "\n",
        "# Show the result\n",
        "overlay.show()\n",
        "\n",
        "# Optionally, save the image with markings\n",
        "overlay.save(\"/content/images/marked_tree3.jpeg\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "hg1aN6CcazRg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db1b78b7-74d2-49cf-b91f-572b068a89bd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training on 8 images, testing on 2 images.\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split the images and paths into training and testing sets\n",
        "train_images, test_images, train_paths, test_paths = train_test_split(images, image_paths, test_size=0.2, random_state=42)\n",
        "\n",
        "print(f\"Training on {len(train_images)} images, testing on {len(test_images)} images.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5v2STMffbz8W"
      },
      "outputs": [],
      "source": [
        "# Assuming the SAM model is already loaded and configured as per your code above\n",
        "diameters = []\n",
        "\n",
        "for image in train_images:\n",
        "    image_np = np.array(image)\n",
        "\n",
        "    # Generate masks using SAM\n",
        "    masks = mask_generator.generate(image_np)\n",
        "\n",
        "    # Identify the tree trunk (largest segmented object)\n",
        "    largest_mask = max(masks, key=lambda x: x['area'])['segmentation']\n",
        "\n",
        "    # Calculate the bounding box of the tree trunk\n",
        "    x, y, w, h = cv2.boundingRect(largest_mask.astype(np.uint8))\n",
        "    tree_trunk_pixel_width = w  # Width of the tree trunk in pixels\n",
        "\n",
        "    # Calculate the real-world width in cm using the corrected formula\n",
        "    real_world_width_cm = (tree_trunk_pixel_width * object_distance_cm) / focal_length_pixels\n",
        "\n",
        "    # Estimate the diameter (assuming the tree trunk is roughly circular)\n",
        "    tree_trunk_diameter_cm = real_world_width_cm\n",
        "\n",
        "    diameters.append(tree_trunk_diameter_cm)\n",
        "\n",
        "print(\"Estimated diameters:\", diameters)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MzM_ZEqGb3xA"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "import numpy as np\n",
        "\n",
        "# Create the input features (pixel widths) and target values (diameters)\n",
        "X_train = np.array([cv2.boundingRect(max(mask_generator.generate(np.array(image)), key=lambda x: x['area'])['segmentation'].astype(np.uint8))[2] for image in train_images]).reshape(-1, 1)\n",
        "y_train = np.array(diameters)\n",
        "\n",
        "# Create and train the linear regression model\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict the diameters for the test images\n",
        "X_test = np.array([cv2.boundingRect(max(mask_generator.generate(np.array(image)), key=lambda x: x['area'])['segmentation'].astype(np.uint8))[2] for image in test_images]).reshape(-1, 1)\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "print(\"Predicted diameters:\", y_pred)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pxjimNUlb5RE"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plot the true vs predicted diameters\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.scatter(X_test, y_pred, color='blue', label='Predicted Diameter')\n",
        "plt.xlabel('Pixel Width of Tree Trunk')\n",
        "plt.ylabel('Diameter (cm)')\n",
        "plt.title('Linear Regression: Predicted Diameter vs Pixel Width')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP50nKTQVZOBWGG1ylS6jR6",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}